{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(file_dir, data):\n",
    "    f = open(file_dir,\"wb\")\n",
    "    pickle.dump(data, f, protocol=4)\n",
    "    f.close()\n",
    "    \n",
    "def read_pkl(file_dir):\n",
    "    f = open(file_dir,\"rb\")\n",
    "    data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file\n",
    "station_group = read_pkl(\"London/station_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a process of getting the flatten Y (pollutions in the future 48 hours)\n",
    "# This is the first step of converting the station_group (station_final.pkl) into X Y (.npy)\n",
    "def flatten_Y(features, ratio = 1, stations = list(station_group.keys()), start = 0):  \n",
    "    \n",
    "    if(start == 0):\n",
    "        length = int(9000 * ratio)\n",
    "    else:\n",
    "        length = 10806\n",
    "        \n",
    "    Y_PM25_list = []\n",
    "    Y_PM10_list = []\n",
    "    Y_NO2_list = []\n",
    "    X_list = []\n",
    "    \n",
    "    for name in station_group:\n",
    "        if name in stations:\n",
    "            # print(name)\n",
    "            PM25_list = station_group[name]['PM25_Concentration'].values\n",
    "            PM10_list = station_group[name]['PM10_Concentration'].values\n",
    "            NO2_list = station_group[name]['NO2_Concentration'].values\n",
    "            \n",
    "            X_this = station_group[name][features].values[start: length] # features_matrix\n",
    "            X_list.append(X_this)\n",
    "            for i in range(start, length):\n",
    "                Y_PM25_list.append(PM25_list[i+1 : i+49])\n",
    "                Y_PM10_list.append(PM10_list[i+1 : i+49])\n",
    "                Y_NO2_list.append(NO2_list[i+1 : i+49])\n",
    "            \n",
    "    Y_PM25 = np.vstack(Y_PM25_list)\n",
    "    Y_PM10 = np.vstack(Y_PM10_list)\n",
    "    Y_NO2 = np.vstack(Y_NO2_list)\n",
    "    X = np.vstack(X_list)\n",
    "    # print(X[:10])\n",
    "    # print(Y_PM25[:10])\n",
    "    return X, Y_PM25, Y_PM10, Y_NO2\n",
    "\n",
    "# This is a one-hot encoding process that can be used to represent different time periods within the next 48 hours.\n",
    "# This is the second step of converting the station_group (station_final.pkl) into  X Y (.npy)\n",
    "def onehot_48_labels(X, Y_PM25, Y_PM10, Y_NO2):\n",
    "    Y_PM25_list = []\n",
    "    Y_PM10_list = []\n",
    "    Y_NO2_list = []\n",
    "    X_list = []\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(Y_PM25.shape[1]):\n",
    "            tmp = np.zeros(48)\n",
    "            tmp[j] = 1\n",
    "            X_list.append(np.hstack((X[i, :], tmp)))\n",
    "            Y_PM25_list.append(Y_PM25[i, j])\n",
    "            Y_PM10_list.append(Y_PM10[i, j])\n",
    "            Y_NO2_list.append(Y_NO2[i, j])\n",
    "    return np.array(X_list), np.array(Y_PM25_list), np.array(Y_PM10_list), np.array(Y_NO2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data (features, k=1, name = 's', start = 0):\n",
    "    s = ['BL0','CD1','CD9','GN0','GN3','GR4','GR9','HV1','KF1','LW2','MY7','ST5','TH4']\n",
    "    X, Y_PM25, Y_PM10, Y_NO2 = flatten_Y(features,ratio = k,stations = s, start = start)\n",
    "    # print(X.shape, Y_PM25.shape,Y_PM10.shape,Y_NO2.shape)\n",
    "    X, Y_PM25, Y_PM10, Y_NO2 = onehot_48_labels(X, Y_PM25, Y_PM10, Y_NO2)\n",
    "    print('Generated data shape: ',X.shape, Y_PM25.shape,Y_PM10.shape,Y_NO2.shape)\n",
    "    # save all of the X Y into .npy file\n",
    "    np.save(\"London/X_\"+name+\".npy\", X)\n",
    "    np.save(\"London/Y_NO2_\"+name+\".npy\", Y_NO2)\n",
    "    np.save(\"London/Y_PM10_\"+name+\".npy\", Y_PM10)\n",
    "    np.save(\"London/Y_PM25_\"+name+\".npy\", Y_PM25)\n",
    "    print('Finish creating and saving the '+name+' version of X, Y_NO2, Y_PM10, and Y_PM25 data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to removing some features in the generated X Y file (.npy), you can delete some of the following elements\n",
    "# And [a,b] is differ from [b,a], which means you can control the feature order of the output data\n",
    "\n",
    "features = ['PM25_Concentration','PM10_Concentration','NO2_Concentration', # feature 0-2\n",
    "            'temperature','pressure','humidity','wind_speed', 'wind_direction', # feature 3-7\n",
    "            'te_0','te_1','te_2','te_3','te_4','te_5','te_6','te_7','te_8','te_9','te_10','te_11','te_12','te_13','te_14','te_15', # feature 8-23\n",
    "            'pr_0','pr_1','pr_2','pr_3','pr_4','pr_5','pr_6','pr_7','pr_8','pr_9','pr_10','pr_11','pr_12','pr_13','pr_14','pr_15', # feature 24-39\n",
    "            'hu_0','hu_1','hu_2','hu_3','hu_4','hu_5','hu_6','hu_7','hu_8','hu_9','hu_10','hu_11','hu_12','hu_13','hu_14','hu_15', # feature 40-55\n",
    "            'wd_0','wd_1','wd_2','wd_3','wd_4','wd_5','wd_6','wd_7','wd_8','wd_9','wd_10','wd_11','wd_12','wd_13','wd_14','wd_15', # feature 56-71\n",
    "            'holiday','time_month','time_week','time_day','time_hour'] # feature 72-76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a testing dataset of X Y data (.npy)\n",
    "# The generated file name is X_test.npy, etc.\n",
    "generate_train_data(features, name = 'test', start = 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data shape:  (68016, 125) (68016,) (68016,) (68016,)\n",
      "Finish creating and saving the s version of X, Y_NO2, Y_PM10, and Y_PM25 data\n"
     ]
    }
   ],
   "source": [
    "# Generate a small-sized version of X Y data (.npy)\n",
    "# The generated file name is X_s.npy, etc.\n",
    "generate_train_data(features, k = 0.01, name = 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also generate a small-sized version of X Y data (.npy) with removing some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data shape:  (674544, 125) (674544,) (674544,) (674544,)\n",
      "Finish creating and saving the m version of X, Y_NO2, Y_PM10, and Y_PM25 data\n"
     ]
    }
   ],
   "source": [
    "# Generate a medium-sized version of X Y data (.npy)\n",
    "# The generated file name is X_m.npy, etc.\n",
    "generate_train_data(features, k = 0.1, name = 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also generate a medium-sized version of X Y data (.npy) with removing some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data shape:  (6742944, 125) (6742944,) (6742944,) (6742944,)\n",
      "Finish creating and saving the all version of X, Y_NO2, Y_PM10, and Y_PM25 data\n"
     ]
    }
   ],
   "source": [
    "# Generate a whole-sized version of X Y data (.npy)\n",
    "# The generated file name is X_all.npy, etc.\n",
    "generate_train_data(features, k = 1, name = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to generate X Y files with other small size, you can change the ratio element\n",
    "# For example, if you change the input ratio 'k' to 0.05 in the generate_train_data function, then you can get the X Y files with 5% of the whole size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img (py36)",
   "language": "python",
   "name": "img"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
